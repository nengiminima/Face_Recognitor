{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bcolz\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.applications import (MobileNetV2,ResNet50)\n",
    "from tensorflow.keras.layers import (Dense,Dropout,Flatten,Input)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''#\"/home/oluwaseun/Documents/Seamfix_projects/project/face_dataset/random_faces/facedataset/badboy1.jpg\"#\"/path/to/an/to/generate/embeddings\"\n",
    "test_dataset = \"/home/oluwaseun/Documents/Seamfix_projects/project/face_dataset/arcface_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batch_size = 128\n",
    "input_size  = 112\n",
    "embd_shape = 512\n",
    "sub_name = 'arc_mobv2' #arc_rec50 or arc_mobv2\n",
    "backbone_type = 'MobileNetV2' # 'ResNet50', 'MobileNetV2'\n",
    "head_type = \"ArcHead\" # 'ArcHead', 'NormHead'\n",
    "is_ccrop = False # central-cropping or not\n",
    "num_classes = 85743 #33432\n",
    "num_samples = 5822653 #2399999\n",
    "w_decay = float(5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backbone(backbone_type='ResNet50', use_pretrain\n",
    "             =True):\n",
    "    \"\"\"Backbone Model\"\"\"\n",
    "    weights = None\n",
    "    if use_pretrain:\n",
    "        weights = 'imagenet'\n",
    "\n",
    "    def backbone(x_in):\n",
    "        if backbone_type == 'ResNet50':\n",
    "            return ResNet50(input_shape=x_in.shape[1:], include_top=False,\n",
    "                            weights=weights)(x_in)\n",
    "        elif backbone_type == 'MobileNetV2':\n",
    "            return MobileNetV2(input_shape=x_in.shape[1:], include_top=False,\n",
    "                               weights=weights)(x_in)\n",
    "        else:\n",
    "            raise TypeError('backbone_type error!')\n",
    "    return backbone\n",
    "\n",
    "\n",
    "def OutputLayer(embd_shape, w_decay=5e-4, name='OutputLayer'):\n",
    "    \"\"\"Output Later\"\"\"\n",
    "    def output_layer(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(embd_shape, kernel_regularizer=tf.keras.regularizers.l2(w_decay) )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "def ArcHead(num_classes, margin=0.5, logist_scale=64, name='ArcHead'):\n",
    "    \"\"\"Arc Head\"\"\"\n",
    "    def arc_head(x_in, y_in):\n",
    "        x = inputs1 = Input(x_in.shape[1:])\n",
    "        y = Input(y_in.shape[1:])\n",
    "        x = ArcMarginPenaltyLogists(num_classes=num_classes,\n",
    "                                    margin=margin,\n",
    "                                    logist_scale=logist_scale)(x, y)\n",
    "        return Model((inputs1, y), x, name=name)((x_in, y_in))\n",
    "    return arc_head\n",
    "\n",
    "def ArcFaceModel(size, channels, num_classes, name, margin, logist_scale, embd_shape,head_type, backbone_type, w_decay, use_pretrain, training):\n",
    "    \"\"\"Arc Face Model\"\"\"\n",
    "    x = inputs = Input([size, size, channels], name='input_image')\n",
    "\n",
    "    x = Backbone(backbone_type=backbone_type, use_pretrain=use_pretrain)(x)\n",
    "\n",
    "    embds = OutputLayer(embd_shape, w_decay=w_decay)(x)\n",
    "    if training:\n",
    "        assert num_classes is not None\n",
    "        labels = Input([], name='label')\n",
    "        if head_type == 'ArcHead':\n",
    "            logist = ArcHead(num_classes=num_classes, margin=margin,\n",
    "                             logist_scale=logist_scale)(embds, labels)\n",
    "        else:\n",
    "            logist = NormHead(num_classes=num_classes, w_decay=w_decay)(embds)\n",
    "        return Model((inputs, labels), logist, name=name)\n",
    "    else:\n",
    "        return Model(inputs, embds, name=name)\n",
    "    \n",
    "    #return Model(inputs, embds, name=name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
    "    \"\"\"Make trainable=False freeze BN for real (the og version is sad).\n",
    "       ref: https://github.com/zzh8829/yolov3-tf2\n",
    "    \"\"\"\n",
    "    def call(self, x, training=False):\n",
    "        if training is None:\n",
    "            training = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)\n",
    "\n",
    "\n",
    "class ArcMarginPenaltyLogists(tf.keras.layers.Layer):\n",
    "    \"\"\"ArcMarginPenaltyLogists\"\"\"\n",
    "    def __init__(self, num_classes, margin=0.5, logist_scale=64, **kwargs):\n",
    "        super(ArcMarginPenaltyLogists, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.margin = margin\n",
    "        self.logist_scale = logist_scale\n",
    "        \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \n",
    "            'num_classes': self.num_classes,\n",
    "            'margin': self.margin,\n",
    "            'logist_scale': self.logist_scale\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_variable(\n",
    "            \"weights\", shape=[int(input_shape[-1]), self.num_classes])\n",
    "        self.cos_m = tf.identity(math.cos(self.margin), name='cos_m')\n",
    "        self.sin_m = tf.identity(math.sin(self.margin), name='sin_m')\n",
    "        self.th = tf.identity(math.cos(math.pi - self.margin), name='th')\n",
    "        self.mm = tf.multiply(self.sin_m, self.margin, name='mm')\n",
    "\n",
    "    def call(self, embds, labels):\n",
    "        normed_embds = tf.nn.l2_normalize(embds, axis=1, name='normed_embd')\n",
    "        normed_w = tf.nn.l2_normalize(self.w, axis=0, name='normed_weights')\n",
    "\n",
    "        cos_t = tf.matmul(normed_embds, normed_w, name='cos_t')\n",
    "        sin_t = tf.sqrt(1. - cos_t ** 2, name='sin_t')\n",
    "\n",
    "        cos_mt = tf.subtract(\n",
    "            cos_t * self.cos_m, sin_t * self.sin_m, name='cos_mt')\n",
    "\n",
    "        cos_mt = tf.where(cos_t > self.th, cos_mt, cos_t - self.mm)\n",
    "\n",
    "        mask = tf.one_hot(tf.cast(labels, tf.int32), depth=self.num_classes,\n",
    "                          name='one_hot_mask')\n",
    "\n",
    "        logists = tf.where(mask == 1., cos_mt, cos_t)\n",
    "        logists = tf.multiply(logists, self.logist_scale, 'arcface_logist')\n",
    "\n",
    "        return logists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_pair(path, name):\n",
    "    carray = bcolz.carray(rootdir=os.path.join(path, name), mode='r')\n",
    "    issame = np.load('{}/{}_list.npy'.format(path, name))\n",
    "\n",
    "    return carray, issame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_data(data_path):\n",
    "    \"\"\"get validation data\"\"\"\n",
    "    lfw, lfw_issame = get_val_pair(data_path, 'lfw_align_112/lfw')\n",
    "    agedb_30, agedb_30_issame = get_val_pair(data_path,'agedb_align_112/agedb_30')\n",
    "\n",
    "    return lfw, lfw_issame, agedb_30, agedb_30_issame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame),\n",
    "                               np.logical_not(actual_issame)))\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
    "\n",
    "    tpr = 0 if (tp + fn == 0) else float(tp) / float(tp + fn)\n",
    "    fpr = 0 if (fp + tn == 0) else float(fp) / float(fp + tn)\n",
    "    acc = float(tp + tn) / dist.size\n",
    "    return tpr, fpr, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame,nrof_folds=10):\n",
    "    assert (embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert (embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    tprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "    best_thresholds = np.zeros((nrof_folds))\n",
    "    indices = np.arange(nrof_pairs)\n",
    "\n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff), 1)\n",
    "\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy( threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "\n",
    "        best_thresholds[fold_idx] = thresholds[best_threshold_index]\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx, threshold_idx], fprs[fold_idx, threshold_idx], _ =  calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy( thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
    "\n",
    "    tpr = np.mean(tprs, 0)\n",
    "    fpr = np.mean(fprs, 0)\n",
    "    return tpr, fpr, accuracy, best_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(embeddings, actual_issame, nrof_folds=10):\n",
    "    # Calculate evaluation metrics\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    embeddings1 = embeddings[0::2]\n",
    "    embeddings2 = embeddings[1::2]\n",
    "    tpr, fpr, accuracy, best_thresholds = calculate_roc(thresholds, embeddings1, embeddings2, np.asarray(actual_issame),nrof_folds=nrof_folds)\n",
    "\n",
    "    return tpr, fpr, accuracy, best_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(x, axis=1):\n",
    "    \"\"\"l2 norm\"\"\"\n",
    "    norm = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "    output = x / norm\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hflip_batch(imgs):\n",
    "    assert len(imgs.shape) == 4\n",
    "    return imgs[:, :, ::-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_val(embedding_size, batch_size, model, carray, issame, nrof_folds=10, is_ccrop=False, is_flip=True):\n",
    "    \"\"\"perform val\"\"\"\n",
    "    embeddings = np.zeros([len(carray), embedding_size])\n",
    "\n",
    "    for idx in tqdm.tqdm(range(0, len(carray), batch_size)):\n",
    "        batch = carray[idx:idx + batch_size]\n",
    "        batch = np.transpose(batch, [0, 2, 3, 1]) * 0.5 + 0.5\n",
    "        if is_ccrop:\n",
    "            batch = ccrop_batch(batch)\n",
    "        if is_flip:\n",
    "            fliped = hflip_batch(batch)\n",
    "            emb_batch = model(batch) + model(fliped)\n",
    "            embeddings[idx:idx + batch_size] = l2_norm(emb_batch)\n",
    "        else:\n",
    "            batch = ccrop_batch(batch)\n",
    "            emb_batch = model(batch)\n",
    "            embeddings[idx:idx + batch_size] = l2_norm(emb_batch)\n",
    "\n",
    "    tpr, fpr, accuracy, best_thresholds = evaluate(embeddings, issame, nrof_folds)\n",
    "\n",
    "    return accuracy.mean(), best_thresholds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ArcFaceModel(size=input_size,channels=3, num_classes=num_classes, name='arcface_model', margin=0.5, logist_scale=64, embd_shape=embd_shape, head_type=head_type, backbone_type = backbone_type,\n",
    "                 w_decay=w_decay, use_pretrain = True, training=False)\n",
    "\n",
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint('./ckpt/ckpt2')\n",
    "print(\"[*] load ckpt from {}\".format(ckpt_path))\n",
    "model.load_weights(ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] load ckpt from ./ckpt/ckpt2/e_5_b_18536.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3b400d8a90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint('./ckpt/ckpt2')\n",
    "print(\"[*] load ckpt from {}\".format(ckpt_path))\n",
    "model.load_weights(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Encode ./data/badboy1.jpg to ./output_embeds.npy\n"
     ]
    }
   ],
   "source": [
    "if img_path:\n",
    "    print(\"[*] Encode {} to ./output_embeds.npy\".format(img_path))\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (input_size, input_size))\n",
    "    img = img.astype(np.float32) / 255.\n",
    "    if len(img.shape) == 3:\n",
    "        img = np.expand_dims(img, 0)\n",
    "        x = model(img)\n",
    "    np.save('./output_embeds.npy', embeds)\n",
    "\n",
    "else:\n",
    "    print(\"[*] Loading LFW, AgeDB30 and CFP-FP...\")\n",
    "    lfw, lfw_issame, agedb_30, agedb_30_issame= get_val_data(test_dataset)\n",
    "    \n",
    "\n",
    "    print(\"[*] Perform Evaluation on LFW...\")\n",
    "    acc_lfw, best_th = perform_val(embd_shape, batch_size, model, lfw, lfw_issame,is_ccrop=False)\n",
    "    print(\"    acc {:.4f}, th: {:.2f}\".format(acc_lfw, best_th))\n",
    "    \n",
    "    print(\"[*] Perform Evaluation on AgeDB30...\")\n",
    "    acc_agedb30, best_th = perform_val(embd_shape, batch_size, model, agedb_30, agedb_30_issame, is_ccrop=False)\n",
    "    print(\"    acc {:.4f}, th: {:.2f}\".format(acc_agedb30, best_th))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
