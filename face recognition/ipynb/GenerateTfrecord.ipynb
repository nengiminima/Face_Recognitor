{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef82f12e",
   "metadata": {},
   "source": [
    "## Download VGG from Gdrive and convert to tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp s3://seamfix-machine-learning-nv02/DeepLearning/Mobilefacenet/512_embed.zip .\n",
    "# !aws s3 cp data/ms1m_vgg.tfrecord s3://seamfix-machine-learning-nv02/DeepLearning/Mobilefacenet/Tfrecord/\n",
    "# !aws s3 cp data/vgg.tfrecord s3://seamfix-machine-learning-nv02/DeepLearning/Mobilefacenet/Tfrecord/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3dd8447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown\n",
    "# !pip install mxnet\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import tqdm\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "# import mxnet as mx\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "from absl import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea475ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-32b47ac34397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mid2range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimgrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecordio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXIndexedRecordIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecordio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/mxnet/recordio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, idx_path, uri, flag, key_type)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMXIndexedRecordIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/mxnet/recordio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, flag)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_open\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/mxnet/recordio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mxrecords exploration\n",
    "file_idx = \"MS1M/faces_emore/train.idx\"\n",
    "file_rec = \"MS1M/faces_emore/train.rec\"\n",
    "index = 0\n",
    "id2range = {}\n",
    "imgrec = mx.recordio.MXIndexedRecordIO(file_idx, file_rec, 'r')\n",
    "item = imgrec.read_idx(index)\n",
    "header, _ = mx.recordio.unpack(item)\n",
    "print(header.label[0]) \n",
    "imgidx = list(range(1, int(header.label[0])))\n",
    "seq_identity = range(int(header.label[0]), int(header.label[1]))\n",
    "print(seq_identity[1] - seq_identity[0])\n",
    "cnt = 0\n",
    "for identity in seq_identity:\n",
    "    cnt += 1\n",
    "    s = imgrec.read_idx(identity)\n",
    "    header, _ = mx.recordio.unpack(s)\n",
    "    a, b = int(header.label[0]), int(header.label[1])\n",
    "    id2range[identity] = (a, b)\n",
    "print('id2range', len(id2range)) #no of labels eg 85742\n",
    "print(len(imgidx)) # view no of data eg 5822653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efab1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#reading TFrecords\n",
    "def _parse_tfrecord(binary_img=False, is_ccrop=False):\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        if binary_img:\n",
    "            features = {'image/source_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "                        'image/data_source': tf.io.FixedLenFeature([], tf.string),\n",
    "                        'image/encoded': tf.io.FixedLenFeature([], tf.string)}\n",
    "            x = tf.io.parse_single_example(tfrecord, features)\n",
    "            x_train = tf.image.decode_jpeg(x['image/encoded'], channels=3)\n",
    "        else:\n",
    "            features = {'image/source_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "                        'image/img_path': tf.io.FixedLenFeature([], tf.string)}\n",
    "            x = tf.io.parse_single_example(tfrecord, features)\n",
    "            image_encoded = tf.io.read_file(x['image/img_path'])\n",
    "            x_train = tf.image.decode_jpeg(image_encoded, channels=3)\n",
    "\n",
    "        y_train = tf.cast(x['image/source_id'], tf.float32)\n",
    "        print(y_train)\n",
    "#         x_train = _transform_images(is_ccrop=is_ccrop)(x_train)\n",
    "        y_train = _transform_targets(y_train)\n",
    "        return (x_train, y_train), y_train\n",
    "    return parse_tfrecord\n",
    "\n",
    "def _transform_images(is_ccrop=False):\n",
    "    def transform_images(x_train):\n",
    "        x_train = tf.image.resize(x_train, (128, 128))\n",
    "        x_train = tf.image.random_crop(x_train, (112, 112, 3))\n",
    "        x_train = tf.image.random_flip_left_right(x_train)\n",
    "        x_train = tf.image.random_saturation(x_train, 0.6, 1.4)\n",
    "        x_train = tf.image.random_brightness(x_train, 0.4)\n",
    "        x_train = x_train / 255\n",
    "        return x_train\n",
    "    return transform_images\n",
    "\n",
    "\n",
    "def _transform_targets(y_train):\n",
    "    return y_train\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_name, batch_size, binary_img=False, shuffle=True, buffer_size=10240,is_ccrop=False):\n",
    "    \"\"\"load dataset from tfrecord\"\"\"\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "    if shuffle:\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = raw_dataset.map(\n",
    "        _parse_tfrecord(binary_img=binary_img, is_ccrop=is_ccrop),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(\n",
    "        buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23418d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "sum(1 for _ in tf.data.TFRecordDataset(\"data/final.tfrecord\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c3e980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(\"data/vgg.tfrecord\")\n",
    "raw_dataset = raw_dataset.repeat()\n",
    "raw_dataset = raw_dataset.shuffle(buffer_size=10240)\n",
    "dataset = raw_dataset.map(\n",
    "    _parse_tfrecord(binary_img=True, is_ccrop=False),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "294a7078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=77595.0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72788f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9124cdf8",
   "metadata": {},
   "source": [
    "## Version 1 method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aaf63d",
   "metadata": {},
   "source": [
    "##### Much slower and memory intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d37a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from mxnet into a sample list \n",
    "def mxrecordio_to_list(file_idx, file_rec, imgidx):\n",
    "    imgrec = mx.recordio.MXIndexedRecordIO(file_idx, file_rec, 'r')\n",
    "    samples = []\n",
    "    for i in imgidx:\n",
    "        item = imgrec.read_idx(i)\n",
    "        header, s = mx.recordio.unpack(item)\n",
    "        x = [header[1],s]\n",
    "        samples.append(x)\n",
    "        if (i % 100000) == 0:\n",
    "            print(i)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f4ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating TFrecord\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def make_example(img_str, source_id):\n",
    "    # Create a dictionary with features that may be relevant.\n",
    "    feature = {'image/source_id': _int64_feature(source_id),\n",
    "               'image/encoded': _bytes_feature(img_str)}\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the image and label from a list and returns a tfrecord\n",
    "def main(_):\n",
    "    samples = mxrecordio_to_list(file_idx, file_rec, imgidx)\n",
    "    random.shuffle(samples)\n",
    "    outputpath = \"data/final.tfrecord\"\n",
    "    with tf.io.TFRecordWriter(outputpath) as writer:\n",
    "        for id_name, img_path in tqdm.tqdm(samples):\n",
    "            #key = img_path.split(\"seamfix-machine-learning/\")[-1]\n",
    "            tf_example = make_example(img_str=img_path, source_id=int(id_name))\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f1f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf999f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ee88bd",
   "metadata": {},
   "source": [
    "## Version 2 method (with shuffling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da8ef7f",
   "metadata": {},
   "source": [
    "##### Much faster and memory intensive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34b9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating TFrecord\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def make_example(img_str, source_id):\n",
    "    # Create a dictionary with features that may be relevant.\n",
    "    feature = {'image/source_id': _int64_feature(source_id),\n",
    "               'image/encoded': _bytes_feature(img_str)}\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c01619db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from mxnet into a sample list \n",
    "def mxrecordio_to_list(paths):\n",
    "    total = 0\n",
    "    samples = []\n",
    "    for path in paths:\n",
    "        file_idx = os.path.join(path, 'train.idx')\n",
    "        file_rec = os.path.join(path, 'train.rec')\n",
    "        imgrec = mx.recordio.MXIndexedRecordIO(file_idx, file_rec, 'r')\n",
    "        \n",
    "        s = imgrec.read_idx(0)\n",
    "        header, _ = mx.recordio.unpack(s)\n",
    "        imgidx = list(range(1, int(header.label[0])))\n",
    "        max_len = len(imgidx)\n",
    "        cnt = 0\n",
    "        \n",
    "        for i in imgidx:\n",
    "            item = imgrec.read_idx(i)\n",
    "            header_index, img = mx.recordio.unpack(item)\n",
    "            x = [total + int(header_index.label), img]\n",
    "            samples.append(x)\n",
    "            cnt += 1\n",
    "            print('%d/%d' % (cnt, max_len), end='\\r')\n",
    "            \n",
    "        seq_identity = range(int(header.label[0]), int(header.label[1]))\n",
    "        total = (len(seq_identity)) + total\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238587b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the image and label from a list and returns a tfrecord\n",
    "def main():\n",
    "    print('write tfrecord from mxrec...')\n",
    "    paths = [\"faces_vgg_112/faces_vgg_112x112\"] #[\"MS1M/faces_emore\", \"faces_vgg_112/faces_vgg_112x112\"]\n",
    "    samples = mxrecordio_to_list(paths)\n",
    "    random.shuffle(samples)\n",
    "    outputpath = \"data/vgg.tfrecord\"\n",
    "    with tf.io.TFRecordWriter(outputpath) as writer:\n",
    "        for id_name, img_path in tqdm.tqdm(samples):\n",
    "            #key = img_path.split(\"seamfix-machine-learning/\")[-1]\n",
    "            tf_example = make_example(img_str=img_path, source_id=int(id_name))\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a908bd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write tfrecord from mxrec...\n",
      "3137807/3137807\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3137807/3137807 [07:18<00:00, 7148.17it/s] \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b8352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da94aec6",
   "metadata": {},
   "source": [
    "## Version 3 method (without shuffling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669e07a",
   "metadata": {},
   "source": [
    "##### Much faster and less memory intensive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929b4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from mxnet into a sample list \n",
    "def mxrecordio_to_list():\n",
    "    total = 0\n",
    "    samples = []\n",
    "    outputpath = \"data/ms1m_.tfrecord\"\n",
    "    paths = [\"MS1M/faces_emore\", \"faces_vgg_112/faces_vgg_112x112\"]\n",
    "    with tf.io.TFRecordWriter(outputpath) as writer:\n",
    "        for path in paths:\n",
    "            file_idx = os.path.join(path, 'train.idx')\n",
    "            file_rec = os.path.join(path, 'train.rec')\n",
    "            imgrec = mx.recordio.MXIndexedRecordIO(file_idx, file_rec, 'r')\n",
    "\n",
    "            s = imgrec.read_idx(0)\n",
    "            header, _ = mx.recordio.unpack(s)\n",
    "            imgidx = list(range(1, int(header.label[0])))\n",
    "            max_len = len(imgidx)\n",
    "            cnt = 0\n",
    "\n",
    "            for i in tqdm.tqdm(imgidx):\n",
    "                item = imgrec.read_idx(i)\n",
    "                header_index, img = mx.recordio.unpack(item)\n",
    "                tf_example = make_example(img_str=img, source_id=total + int(header_index.label))\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "                cnt += 1\n",
    "#                 print('%d/%d' % (cnt, max_len), end='\\r')\n",
    "\n",
    "            seq_identity = range(int(header.label[0]), int(header.label[1]))\n",
    "            total = (len(seq_identity)) + total\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b071eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5822653/5822653 [1:02:06<00:00, 1562.34it/s]\n",
      " 82%|████████▏ | 2580241/3137807 [58:05<11:18, 821.47it/s]  "
     ]
    }
   ],
   "source": [
    "mxrecordio_to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa4b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1aa02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e13cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34721c71",
   "metadata": {},
   "source": [
    "## Version 4 method (with shuffling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93323a",
   "metadata": {},
   "source": [
    "##### This peteryuX version. This works with images in directory rather than mxrecord format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5248341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def make_example(img_str, source_id, filename):\n",
    "    # Create a dictionary with features that may be relevant.\n",
    "    feature = {'image/source_id': _int64_feature(source_id),\n",
    "               'image/filename': _bytes_feature(filename),\n",
    "               'image/encoded': _bytes_feature(img_str)}\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def main(dataset_path):\n",
    "\n",
    "    if not os.path.isdir(dataset_path):\n",
    "        logging.info('Please define valid dataset path.')\n",
    "    else:\n",
    "        logging.info('Loading {}'.format(dataset_path))\n",
    "\n",
    "    samples = []\n",
    "    logging.info('Reading data list...')\n",
    "    for id_name in tqdm.tqdm(os.listdir(dataset_path)):\n",
    "        img_paths = glob.glob(os.path.join(dataset_path, id_name, '*.jpg'))\n",
    "        for img_path in img_paths:\n",
    "            filename = os.path.join(id_name, os.path.basename(img_path))\n",
    "            samples.append((img_path, id_name, filename))\n",
    "    random.shuffle(samples)\n",
    "\n",
    "    logging.info('Writing tfrecord file...')\n",
    "    outputpath = \"data/peteryuX_ms1m.tfrecord\"\n",
    "    with tf.io.TFRecordWriter(outputpath) as writer:\n",
    "        for img_path, id_name, filename in tqdm.tqdm(samples):\n",
    "            tf_example = make_example(img_str=open(img_path, 'rb').read(),\n",
    "                                      source_id=int(id_name),\n",
    "                                      filename=str.encode(filename))\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fd761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85742/85742 [00:40<00:00, 2099.65it/s]\n",
      " 38%|███▊      | 2200520/5822653 [33:44<44:31, 1356.03it/s]  "
     ]
    }
   ],
   "source": [
    "main('data/MS1M/imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0970aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85742"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "len(os.listdir('data/MS1M/imgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfd0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
